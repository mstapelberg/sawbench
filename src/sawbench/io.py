"""Module for handling input/output operations for sawbench.

This module provides functions for loading experimental FFT data from HDF5 files
and EBSD data from various formats (e.g., .ctf, .ang) using the defdap library.
It also includes a utility for reading Oxford Instruments .ctf files directly.
"""
import pandas as pd
import h5py
import numpy as np
from defdap import ebsd
from typing import Tuple, Dict, List, Optional, Union # Added Union for ebsd.Map | None
from io import StringIO

def read_ctf(filepath: str) -> Tuple[Dict[str, List[str]], pd.DataFrame]:
    """Reads an Oxford Instruments .ctf file.

    Parses the header and data sections of a .ctf (channel text file)
    typically generated by Oxford Instruments EBSD systems.

    Args:
        filepath (str): The path to the .ctf file.

    Returns:
        Tuple[Dict[str, List[str]], pd.DataFrame]: A tuple containing:
            - header (Dict[str, List[str]]): A dictionary where keys are header
              field names (e.g., 'JobMode', 'XCells') and values are lists
              of strings from the corresponding header line.
            - df (pd.DataFrame): A pandas DataFrame containing the EBSD data.
              The columns are named according to the .ctf file's data header,
              typically including 'Phase', 'X', 'Y', 'Euler1', 'Euler2', 'Euler3',
              'MAD', 'BC', 'BS'. Euler angles are in degrees.

    Raises:
        ValueError: If the column header line (expected to contain 'Euler1',
                    'Euler2', 'Euler3') cannot be found in the file.
        FileNotFoundError: If the specified filepath does not exist.

    Examples:
        >>> # This is a conceptual example, as it requires a .ctf file.
        >>> # Assume 'example.ctf' exists and is a valid CTF file.
        >>> # header_info, ebsd_data_df = read_ctf('example.ctf')
        >>> # print(header_info.get('XCells')) # e.g., ['100']
        >>> # print(ebsd_data_df.head())
        
    Notes:
        The function attempts to automatically find the start of the data block
        after the header. It assumes that data lines start with a digit.
        Column names for the DataFrame are extracted from the line containing
        'Euler1', 'Euler2', and 'Euler3'.
    """
    header: Dict[str, List[str]] = {}
    column_names: Optional[List[str]] = None
    data_start: Optional[int] = None
    
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except FileNotFoundError:
        print(f"ERROR: CTF file not found at {filepath}")
        raise

    # Parse header
    for i, line in enumerate(lines):
        line = line.strip()
        if not line:
            continue
        # Key-value header lines (typically separated by tab)
        if '\\t' in line:
            parts = line.split('\\t')
            if len(parts) >= 2:
                header[parts[0]] = parts[1:]
        # Find the column header line (look for 'Euler1', 'Euler2', 'Euler3')
        # This is a common signature for the data header in CTF files.
        if 'Euler1' in line and 'Euler2' in line and 'Euler3' in line:
            column_names = line.split() # Split by any whitespace
            data_start = i + 1
            break
            
    if column_names is None or data_start is None:
        raise ValueError(
            "Could not find column names (expected 'Euler1', 'Euler2', 'Euler3') "
            f"in .ctf file: {filepath}"
        )
        
    # Find the actual start of numeric data, skipping any intermediate non-data lines
    # (e.g., phase information lines sometimes appear after the column header)
    first_data_line_index = -1
    for j in range(data_start, len(lines)):
        stripped_line = lines[j].strip()
        # Check if the line is not empty and starts with a digit or a minus sign (for negative coordinates)
        if stripped_line and (stripped_line[0].isdigit() or stripped_line.startswith('-')):
            first_data_line_index = j
            break
            
    if first_data_line_index == -1:
        raise ValueError(f"Could not find the start of the data block in .ctf file: {filepath}")

    data_str = ''.join(lines[first_data_line_index:])
    # Use StringIO to treat the string data as a file for pd.read_csv
    # sep=r'\\s+' handles one or more whitespace characters as delimiters
    df = pd.read_csv(StringIO(data_str), sep=r'\\s+', names=column_names, engine='python')
    return header, df

def load_fft_data_from_hdf5(
    hdf5_path: str
) -> Optional[Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, Tuple[int, int]]]:
    """Loads experimental FFT (Fast Fourier Transform) data from an HDF5 file.

    Assumes a specific HDF5 structure where datasets for frequency, coordinates,
    and amplitude data are present.

    Args:
        hdf5_path (str): Path to the HDF5 file.

    Returns:
        Optional[Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, Tuple[int, int]]]:
        A tuple containing:
            - exp_freq_axis (np.ndarray): 1D array of frequency values (Hz).
            - exp_x_coords_raw (np.ndarray): 1D array of raw X coordinates.
            - exp_y_coords_raw (np.ndarray): 1D array of raw Y coordinates.
            - exp_amplitude_data (np.ndarray): 3D array of amplitude data,
              with frequency as the first axis (shape: [freq, Y, X]).
            - (Ny_exp, Nx_exp) (Tuple[int, int]): Dimensions of the experimental
              grid (number of Y points, number of X points).
        Returns None if the file is not found, a dataset is missing, or another
        error occurs during loading.

    Examples:
        >>> # Conceptual example, requires 'exp_data.h5' with correct structure
        >>> # fft_results = load_fft_data_from_hdf5('exp_data.h5')
        >>> # if fft_results:
        >>> #     freq_axis, x_coords, y_coords, amplitudes, (Ny, Nx) = fft_results
        >>> #     print(f"Data shape: {amplitudes.shape}, Grid: {Ny}x{Nx}")
        >>> # else:
        >>> #     print("Failed to load FFT data.")

    Notes:
        The function expects the HDF5 file to contain datasets named:
        '/freq', '/X', '/Ycoord', and '/amplitude'.
        It attempts to reorder the amplitude data so that the frequency dimension
        is always the first axis.
    """
    try:
        with h5py.File(hdf5_path, 'r') as h5:
            if "/freq" not in h5 or "/X" not in h5 or "/Ycoord" not in h5 or "/amplitude" not in h5:
                print(f"ERROR: One or more required datasets not found in {hdf5_path}")
                return None

            exp_freq_axis: np.ndarray = h5["/freq"][:]
            exp_x_coords_raw: np.ndarray = h5["/X"][:]
            exp_y_coords_raw: np.ndarray = h5["/Ycoord"][:]
            exp_amplitude_raw = h5["/amplitude"] # Keep as HDF5 dataset for now

            # Determine the index of the frequency axis in the raw amplitude data
            freq_axis_idx_exp = -1
            for i, dim_size in enumerate(exp_amplitude_raw.shape):
                if dim_size == len(exp_freq_axis):
                    freq_axis_idx_exp = i
                    break
            
            if freq_axis_idx_exp == -1:
                print("ERROR: Frequency axis dimension mismatch in experimental amplitude data.")
                return None
            
            # Ensure frequency is the first axis by moving it if necessary
            # Load the full data into memory when moving axis or if it's already first
            exp_amplitude_data_loaded: np.ndarray = exp_amplitude_raw[()] 
            if freq_axis_idx_exp != 0:
                exp_amplitude_data = np.moveaxis(exp_amplitude_data_loaded, freq_axis_idx_exp, 0)
            else:
                exp_amplitude_data = exp_amplitude_data_loaded

        # Infer Ny and Nx from the shape of the amplitude data (after moving freq axis)
        # Expected shape: (num_freq_points, Ny_exp, Nx_exp)
        if exp_amplitude_data.ndim != 3:
            print(f"ERROR: Unexpected dimensionality for amplitude data: {exp_amplitude_data.ndim}")
            return None
        Ny_exp = exp_amplitude_data.shape[1]
        Nx_exp = exp_amplitude_data.shape[2]
        
        return exp_freq_axis, exp_x_coords_raw, exp_y_coords_raw, exp_amplitude_data, (Ny_exp, Nx_exp)
    
    except FileNotFoundError:
        print(f"ERROR: Experimental HDF5 data file not found at {hdf5_path}")
        return None
    except Exception as e:
        print(f"Error loading experimental FFT data from HDF5: {e}")
        return None

def load_ebsd_map(
    file_path: str,
    data_type: str = "OxfordText",
    boundary_def: float = 5.0,
    min_grain_size: int = 10
) -> Optional[ebsd.Map]:
    """Loads and processes EBSD (Electron Backscatter Diffraction) data using defdap.

    This function wraps the defdap library's EBSD map loading and initial
    processing steps, including building a quaternion array, finding grain
    boundaries, and identifying grains.

    Args:
        file_path (str): Path to the EBSD data file (e.g., .ctf, .ang, .h5).
        data_type (str, optional): Type of EBSD file, passed to `defdap.ebsd.Map`.
            Common values include "OxfordText" (for .ctf), "ang" (for .ang files).
            Defaults to "OxfordText".
        boundary_def (float, optional): Misorientation angle in degrees used to define
            grain boundaries. Defaults to 5.0.
        min_grain_size (int, optional): Minimum number of pixels (data points)
            for a contiguous region of similar orientation to be considered a grain.
            Defaults to 10.

    Returns:
        Optional[defdap.ebsd.Map]: A processed `defdap.ebsd.Map` object containing
        the EBSD data, grain information, and boundaries. Returns `None` if an
        error occurs during loading or processing (e.g., file not found,
        defdap internal error).

    Examples:
        >>> # Conceptual example, requires 'ebsd_data.ctf'
        >>> # ebsd_map = load_ebsd_map('ebsd_data.ctf', data_type="OxfordText")
        >>> # if ebsd_map:
        >>> #     print(f"Loaded EBSD map with {len(ebsd_map.grainList)} grains.")
        >>> #     print(f"Step size: {ebsd_map.stepSize} um") # Assuming stepSize is in um
        >>> # else:
        >>> #     print("Failed to load EBSD map.")
        
    Notes:
        The `defdap` library must be installed and configured correctly for this
        function to work. The function prints status messages during processing.
        Error handling is included for `FileNotFoundError` and general exceptions
        from `defdap`.
    """
    try:
        print(f"Loading EBSD map from: {file_path} (type: {data_type})")
        # Initialize the EBSD map object using defdap
        ebsd_map_obj = ebsd.Map(file_path, dataType=data_type)
        
        # Convert crystal orientations to quaternions for internal calculations
        ebsd_map_obj.buildQuatArray()
        print(f"EBSD Phases found: {[phase.name for phase in ebsd_map_obj.phases]}")
        
        # Identify grain boundaries based on the misorientation threshold
        print(f"Finding boundaries with misorientation definition: {boundary_def}°")
        ebsd_map_obj.findBoundaries(boundDef=boundary_def)
        
        # Identify grains based on the minimum grain size
        # This step also populates the grainIDMap attribute in the ebsd_map_obj
        print(f"Finding grains with minimum size: {min_grain_size} pixels")
        ebsd_map_obj.findGrains(minGrainSize=min_grain_size)
        print(f"Identified {len(ebsd_map_obj.grainList)} EBSD grains.")
        
        return ebsd_map_obj
        
    except FileNotFoundError:
        print(f"ERROR: EBSD data file not found at {file_path}")
        return None
    except Exception as e:
        # Catching a general exception as defdap might raise various errors
        print(f"Error processing EBSD data with defdap: {e}")
        return None